{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aca6839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-04 13:49:36,121 [INFO] \n",
      "Limited Total Variation Regularization Support Detected! \n",
      "---> CVXPY is not installed. \n",
      "---> Many Total Variation Methods require CVXPY including: \n",
      "---> velocity, acceleration, jerk, jerk_sliding, smooth_acceleration\n",
      "---> Please install CVXPY to use these methods.\n",
      "---> Recommended to also install MOSEK and obtain a MOSEK license.\n",
      "You can still use: total_variation_regularization.iterative_velocity\n",
      "\n",
      "2025-03-04 13:49:36,122 [INFO] \n",
      "Limited Linear Model Support Detected! \n",
      "---> PYCHEBFUN is not installed. \n",
      "---> Install pychebfun to use chebfun derivatives (https://github.com/pychebfun/pychebfun/) \n",
      "You can still use other methods \n",
      "\n",
      "2025-03-04 13:49:36,123 [INFO] \n",
      "Limited Linear Model Support Detected! \n",
      "---> CVXPY is not installed. \n",
      "---> Install CVXPY to use lineardiff derivatives \n",
      "You can still use other methods \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import bootstrap\n",
    "import sys\n",
    "import warnings\n",
    "from copy import deepcopy,copy\n",
    "#from ipywidgets import IntProgress\n",
    "#from itertools import chain\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import os\n",
    "#from sympy import sympify,latex,Float\n",
    "import random\n",
    "from math import ceil,sqrt\n",
    "#import seaborn as sbrn\n",
    "from scipy.optimize import curve_fit\n",
    "# Catch stout\n",
    "#from io import StringIO \n",
    "import sys\n",
    "import pynumdiff\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "# Import Machine Scientist ODE\n",
    "from importlib.machinery import SourceFileLoader\n",
    "\n",
    "# Get the absolute path of the script's directory\n",
    "script_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# Define the relative path to the module\n",
    "relative_module_path = \"rguimera-machine-scientist/machinescientist_ode.py\"\n",
    "path = os.path.join(script_dir, relative_module_path)\n",
    "ms_ode = SourceFileLoader(\"ms\", path).load_module()\n",
    "\n",
    "# Import Machine Scientist FIT\n",
    "from importlib.machinery import SourceFileLoader\n",
    "\n",
    "# Get the absolute path of the script's directory\n",
    "script_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# Define the relative path to the module\n",
    "relative_module_path = \"rguimera-machine-scientist/machinescientist_fit.py\"\n",
    "path = os.path.join(script_dir, relative_module_path)\n",
    "ms_fit = SourceFileLoader(\"ms_fit\", path).load_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127de7dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005\n",
      "0.005_1.pkl\n",
      "true (B + -((B ** 2))) -B**2+B -453.924784793266 ['B']\n",
      "bms (_a7_ * ((_a7_ + B) * B)) -449.812144432682\n",
      "8.833857011673066e-05 0.0054038358363513155\n",
      "lernable\n",
      "test 0.99782656622261\n",
      "0.99782656622261\n",
      "False\n",
      "False\n",
      "0.005_11.pkl\n",
      "true (B + -((B ** 2))) -B**2+B -445.635212260140 ['B']\n",
      "bms (_a6_ * (B * (B + _a6_))) -441.502568677809\n",
      "1.6091356578449281e-06 0.006024868197727184\n",
      "lernable\n",
      "test 0.9978203648042275\n",
      "0.9978605209569461\n",
      "False\n",
      "False\n",
      "0.005_14.pkl\n",
      "Updating mdl ode model with exhaustive model: (_a7_ * (((B + _a7_) * _a1_) * B)) ((_a0_ * B) + (_a1_ * (B ** 2)))\n",
      "true (B + -((B ** 2))) -B**2+B -455.173461489428 ['B']\n",
      "bms ((_a0_ * B) + (_a1_ * (B ** 2))) -445.062326753928\n",
      "0.00016567611640382 0.005433895969015983\n",
      "lernable\n",
      "test 0.9978051277843496\n",
      "1.0018914226384283\n",
      "False\n",
      "False\n",
      "0.005_23.pkl\n",
      "true (B + -((B ** 2))) -B**2+B -460.706678708674 ['B']\n",
      "bms (B + -((B ** 2))) -460.706678708674\n",
      "0.0 0.005354787457673466\n",
      "lernable\n",
      "test 0.9978270562669705\n",
      "0.998854317223623\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Loop over data files\n",
    "\n",
    "files=[f for f in os.listdir('noise_data/')]\n",
    "#print(files)\n",
    "sigmas=[0.005,0.006,0.007,0.008,0.009,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.2,0.3,0.4,0.5]\n",
    "\n",
    "def Euler_integral(model,x0,t):\n",
    "    \n",
    "    def ode(y):\n",
    "        # X Lambda input\n",
    "        predict = model.predict({'A0':pd.DataFrame(data={'B':[y]})})\n",
    "        return predict['A0'].to_numpy()[0]\n",
    "    \n",
    "    x=x0\n",
    "    t_x=[x0]\n",
    "    h=(t[1]-t[0])\n",
    "    for i in range(len(t)-1):\n",
    "        diff=ode(x)\n",
    "        x=x+h*diff\n",
    "        t_x.append(x)\n",
    "    return np.array(t_x,dtype=np.float64)\n",
    "\n",
    "def func(x,x0):\n",
    "    eval=Euler_integral(model_to_fit,x0,t)\n",
    "    return eval\n",
    "\n",
    "\n",
    "s_array=[]\n",
    "ode_lernability=[]\n",
    "ode_lernability_err=[]\n",
    "fit_lernability=[]\n",
    "fit_lernability_err=[]\n",
    "smooth_lernability=[]\n",
    "smooth_lernability_err=[]\n",
    "\n",
    "true_best_error_ode_final=[]\n",
    "data_best_error_ode_final=[]\n",
    "data_best_error_ode_final_err=[]\n",
    "\n",
    "true_best_error_fit_final=[]\n",
    "data_best_error_fit_final=[]\n",
    "data_best_error_fit_final_err=[]\n",
    "\n",
    "true_best_error_smth_final=[]\n",
    "data_best_error_smth_final=[]\n",
    "data_best_error_smth_final_err=[]\n",
    "\n",
    "corpus_true=['(B + ((-(B)) * B))','(B + (-(pow2(B))))','(B + -((B ** 2)))',\n",
    "             '(((_a1_ + B) * B) / _a1_)','(B + (-(B) ** 2))','((_a1_ * (B ** 2)) + B)',\n",
    "             '((B + _a5_) * -(B))','-(((_a6_ + B) * B))','(B + ((B ** 2) * _a0_))'\n",
    "            ]\n",
    "\n",
    "for sigma in sigmas:\n",
    "    count_ode=0\n",
    "    l_ode=0\n",
    "    count_fit=0\n",
    "    l_fit=0\n",
    "    count_smth=0\n",
    "    l_smth=0\n",
    "    \n",
    "    true_best_error_ode=[]\n",
    "    data_best_error_ode=[]\n",
    "    \n",
    "    true_best_error_fit=[]\n",
    "    data_best_error_fit=[]\n",
    "    \n",
    "    true_best_error_smth=[]\n",
    "    data_best_error_smth=[]\n",
    "    \n",
    "    print(sigma)\n",
    "    \n",
    "    for file in [f for f in files if f.startswith(str(sigma)+'_')]:\n",
    "        #Lernability for ODE\n",
    "        print(file)\n",
    "        try:\n",
    "            # True Model ODEint\n",
    "            data=pd.read_pickle('noise_data/'+file)\n",
    "            x={}\n",
    "            y={}\n",
    "            y['A0']=pd.Series(deepcopy(data['B']))\n",
    "            x['A0']=deepcopy(data)\n",
    "            XLABS = ['B']\n",
    "            params = 8\n",
    "            \"\"\"str_model= '(B - (pow2(B))'\n",
    "            true_model2 = ms_ode.from_string_model(x,y,str_model,1,8,['B'],silence=True)\n",
    "            str_model= '(B + ((-(B)) * B))'\n",
    "            true_model1 = ms_ode.from_string_model(x,y,str_model,1,8,['B'],silence=True)\n",
    "            str_model= '(B + (-(pow2(B))))'\n",
    "            true_model = ms_ode.from_string_model(x,y,str_model,1,8,['B'],silence=True)\"\"\"\n",
    "            list_dl_trues=[ms_ode.from_string_model(x,y,str_model,1,8,['B'],silence=True) for str_model in corpus_true]\n",
    "            true_model = min(list_dl_trues, key=lambda x: x.E)\n",
    "            \n",
    "            #print(true_model2.E,true_model2.EP,true_model1.E,true_model1.EP,true_model.E,true_model.EP)\n",
    "            #Load sampled model\n",
    "            with open(f'./noise_data_res_ODE/{file}', 'rb') as f:\n",
    "                # A new file will be created\n",
    "                best_model=pickle.load(f)\n",
    "            try:\n",
    "                with open(f'./noise_data_res_exhaustive_new/BMS_{file[:-4]}.pkl', 'rb') as f:\n",
    "                    # A new file will be created\n",
    "                    bms_exh=pickle.load(f)\n",
    "                if best_model.E>bms_exh.E:\n",
    "                    print('Updating mdl ode model with exhaustive model:',best_model,bms_exh)\n",
    "                    del best_model\n",
    "                    best_model = deepcopy(bms_exh)\n",
    "                    del bms_exh\n",
    "            except:\n",
    "                pass\n",
    "            #best_model.get_energy(bic=True,reset=True)\n",
    "            print('true',true_model,true_model.canonical(),true_model.E,true_model.variables)\n",
    "            #print(true_model.par_values)\n",
    "            #print(true_model.x0[str(true_model)])\n",
    "            print('bms',best_model,best_model.E)\n",
    "            #print(best_model.par_values)\n",
    "            #print(best_model.x0[str(best_model)])\n",
    "            \n",
    "            t=data.t.to_numpy()\n",
    "            model_to_fit=true_model\n",
    "            popt,pcov=curve_fit(func, [0], data['B'].to_numpy(), p0=[0.01])\n",
    "            #int_true=Euler_integral(true_model,true_model.x0[str(true_model)]['A0'],data.t.to_numpy())\n",
    "            int_true=Euler_integral(true_model,popt[0],data.t.to_numpy())\n",
    "            \n",
    "            model_to_fit=best_model\n",
    "            popt,pcov=curve_fit(func, [0], data['B'].to_numpy(), p0=[0.01])\n",
    "            \n",
    "            #int_best=Euler_integral(best_model,best_model.x0[str(best_model)]['A0'],data.t.to_numpy())\n",
    "            int_best=Euler_integral(best_model,popt[0],data.t.to_numpy())\n",
    "            \n",
    "            \n",
    "            true_best_err=np.sqrt(np.mean((int_true-int_best)**2))\n",
    "            data_best_err=np.sqrt(np.mean((data.B.to_numpy()-int_best)**2))\n",
    "            \n",
    "            if not np.isinf(int_true[-1]) and not np.isinf(int_best[-1]):\n",
    "\n",
    "                print(true_best_err,data_best_err)\n",
    "\n",
    "                true_best_error_ode.append(true_best_err)\n",
    "                data_best_error_ode.append(data_best_err)\n",
    "            else:\n",
    "                print(true_best_err,data_best_err)\n",
    "                print(popt)\n",
    "                print(int_true)\n",
    "                print(int_best)\n",
    "                print('RMSE error in ODE:')\n",
    "            if true_best_err>10. or data_best_err>10.:\n",
    "                print('Check BMS model ODE:',file,str(best_model),best_model.E,true_best_err,data_best_err)\n",
    "            \n",
    "            count_ode+=1\n",
    "            if best_model.E>=true_model.E:\n",
    "                l_ode+=1\n",
    "            elif np.isclose(np.float64(best_model.E),np.float64(true_model.E), rtol=1e-05, atol=1e-08):\n",
    "                l_ode+=1\n",
    "            else:\n",
    "                print('non lernable')\n",
    "                print('ODE***********************',str(true_model),true_model.E,str(best_model),best_model.E)\n",
    "                print(best_model.par_values)\n",
    "            #print('ODE',file,'true',true_model.E,'mdl',best_model.E)\n",
    "        except Exception as e:\n",
    "            print('Error in ODE:',e)\n",
    "            print(traceback.format_exc())\n",
    "            pass\n",
    "            \n",
    "        try:\n",
    "            # True Model Fit deriv\n",
    "            data=pd.read_pickle('noise_data/'+file)\n",
    "            x={}\n",
    "            y={}\n",
    "            with open(f'./noise_data_res_fit/{file}', 'rb') as f:\n",
    "                # A new file will be created\n",
    "                best_model=pickle.load(f)\n",
    "            try:\n",
    "                with open(f'./noise_data_res_exhaustive_new/BMS_fit_{file[:-4]}.pkl', 'rb') as f:\n",
    "                    # A new file will be created\n",
    "                    bms_exh=pickle.load(f)\n",
    "                if best_model.E>bms_exh.E:\n",
    "                    print('Updating mdl ode model with exhaustive model:',best_model,bms_exh)\n",
    "                    del best_model\n",
    "                    best_model = deepcopy(bms_exh)\n",
    "                    del bms_exh\n",
    "            except:\n",
    "                pass\n",
    "            x=best_model.x\n",
    "            y=best_model.y\n",
    "            XLABS = ['B']\n",
    "            params = 8\n",
    "            \"\"\"str_model= '(B + ((-(B)) * B))'\n",
    "            str_model= '(B + (-(pow2(B))))'\n",
    "            true_model = ms_fit.from_string_model(x,y,str_model,1,8,['B'],silence=True)\"\"\"\n",
    "            \n",
    "            list_dl_trues=[ms_fit.from_string_model(x,y,str_model,1,8,['B'],silence=True) for str_model in corpus_true]\n",
    "            true_model = min(list_dl_trues, key=lambda x: x.E)\n",
    "            #Load sampled model\n",
    "            t=data.t.to_numpy()\n",
    "            model_to_fit=true_model\n",
    "            popt,pcov=curve_fit(func, [0], data['B'].to_numpy(), p0=[0.01])\n",
    "            \n",
    "            int_true=Euler_integral(true_model,popt[0],data.t.to_numpy())\n",
    "            \n",
    "            model_to_fit=best_model\n",
    "            popt,pcov=curve_fit(func, [0], data['B'].to_numpy(), p0=[0.01])\n",
    "            \n",
    "            int_best=Euler_integral(best_model,popt[0],data.t.to_numpy())\n",
    "            \n",
    "            \n",
    "            true_best_err=np.sqrt(np.mean((int_true-int_best)**2))\n",
    "            data_best_err=np.sqrt(np.mean((data.B.to_numpy()-int_best)**2))\n",
    "\n",
    "            print('test',int_true[-1])\n",
    "            print(int_best[-1])\n",
    "            print(np.isinf(int_true[-1]))\n",
    "            print(np.isinf(int_best[-1]))\n",
    "            \n",
    "            if not np.isinf(int_true[-1]) and not np.isinf(int_best[-1]):\n",
    "                \n",
    "                true_best_error_fit.append(true_best_err)\n",
    "                data_best_error_fit.append(data_best_err)\n",
    "            else:\n",
    "                print(true_best_err,data_best_err)\n",
    "                print(popt)\n",
    "                #print(int_true)\n",
    "                #print(int_best)\n",
    "                print('RMSE error in FIT:')\n",
    "            if true_best_err>10. or data_best_err>10.:\n",
    "                print('Check BMS model FIT:',file,str(best_model),best_model.E,true_best_err,data_best_err)\n",
    "                \n",
    "            count_fit+=1\n",
    "            if best_model.E>=true_model.E:\n",
    "                l_fit+=1\n",
    "            elif np.isclose(np.float64(best_model.E),np.float64(true_model.E), rtol=1e-05, atol=1e-08):\n",
    "                l_fit+=1\n",
    "            else:\n",
    "                print('FIT***************',str(true_model),true_model.E,str(best_model),best_model.E)\n",
    "                print(best_model.par_values)\n",
    "            #print('FIT',file,'true',true_model.E,'mdl',best_model.E)\n",
    "        except Exception as e:\n",
    "            print('Error in FIT:',e)\n",
    "            print(traceback.format_exc())\n",
    "            print(true_best_err,type(true_best_err))\n",
    "            print(data_best_err,type(data_best_err))\n",
    "            pass\n",
    "            \n",
    "            \n",
    "        try:\n",
    "            # True Model Fit deriv smooth\n",
    "            data=pd.read_pickle('noise_data/'+file)\n",
    "            x={}\n",
    "            y={}\n",
    "            with open(f'./noise_data_res_fit_smooth/{file}', 'rb') as f:\n",
    "                # A new file will be created\n",
    "                best_model=pickle.load(f)\n",
    "            try:\n",
    "                with open(f'./noise_data_res_exhaustive_new/BMS_smooth_{file[:-4]}.pkl', 'rb') as f:\n",
    "                    # A new file will be created\n",
    "                    bms_exh=pickle.load(f)\n",
    "                if best_model.E>bms_exh.E:\n",
    "                    print('Updating mdl ode model with exhaustive model:',best_model,bms_exh)\n",
    "                    del best_model\n",
    "                    best_model = deepcopy(bms_exh)\n",
    "                    del bms_exh\n",
    "            except:\n",
    "                pass\n",
    "            x=best_model.x\n",
    "            y=best_model.y\n",
    "            XLABS = ['B']\n",
    "            params = 8\n",
    "            \n",
    "            list_dl_trues=[ms_fit.from_string_model(x,y,str_model,1,8,['B'],silence=True) for str_model in corpus_true]\n",
    "            true_model = min(list_dl_trues, key=lambda x: x.E)\n",
    "            #Load sampled model\n",
    "            \n",
    "            t=data.t.to_numpy()\n",
    "            model_to_fit=true_model\n",
    "            popt,pcov=curve_fit(func, [0], data['B'].to_numpy(), p0=[0.01])\n",
    "            \n",
    "            int_true=Euler_integral(true_model,popt[0],data.t.to_numpy())\n",
    "            \n",
    "            model_to_fit=best_model\n",
    "            popt,pcov=curve_fit(func, [0], data['B'].to_numpy(), p0=[0.01])\n",
    "            \n",
    "            int_best=Euler_integral(best_model,popt[0],data.t.to_numpy())\n",
    "            \n",
    "            \n",
    "            true_best_err=np.sqrt(np.mean((int_true-int_best)**2))\n",
    "            data_best_err=np.sqrt(np.mean((data.B.to_numpy()-int_best)**2))\n",
    "            \n",
    "            if not np.isinf(int_true[-1]) and not np.isinf(int_best[-1]):\n",
    "                \n",
    "                true_best_error_smth.append(true_best_err)\n",
    "                data_best_error_smth.append(data_best_err)\n",
    "            else:\n",
    "                print(true_best_err,data_best_err)\n",
    "                print(popt)\n",
    "                #print(int_true)\n",
    "                #print(int_best)\n",
    "                print('RMSE error in SMTH:')\n",
    "            if true_best_err>10. or data_best_err>10.:\n",
    "                print('Check BMS model SMTH:',file,str(best_model),best_model.E,true_best_err,data_best_err)\n",
    "            #Load sampled model\n",
    "            \n",
    "            count_smth+=1\n",
    "            if best_model.E>=true_model.E:\n",
    "                l_smth+=1\n",
    "            elif np.isclose(np.float64(best_model.E),np.float64(true_model.E), rtol=1e-05, atol=1e-08):\n",
    "                l_smth+=1\n",
    "            else:\n",
    "                print('SMTH*******************',str(true_model),true_model.E,str(best_model),best_model.E)\n",
    "                print(best_model.par_values)\n",
    "            #print('SMTH',file,'true',true_model.E,'mdl',best_model.E)\n",
    "        except Exception as e:\n",
    "            print('Error in SMOOTH:',e)\n",
    "            print(traceback.format_exc())\n",
    "            print(true_best_err,type(true_best_err))\n",
    "            print(data_best_err,type(data_best_err))\n",
    "            \n",
    "            pass\n",
    "            \n",
    "    # appending lernability fracction\n",
    "    s_array.append(sigma)\n",
    "    ode_lernability.append(np.divide(float(l_ode),float(count_ode)))\n",
    "    print(len([1]*l_ode+[0]*(count_ode-l_ode)),[1]*l_ode+[0]*(count_ode-l_ode))\n",
    "    ode_lernability_err.append(bootstrap(([1]*l_ode+[0]*(count_ode-l_ode),), np.mean, confidence_level=0.95, method='percentile').standard_error)\n",
    "    fit_lernability.append(np.divide(float(l_fit),float(count_fit)))\n",
    "    fit_lernability_err.append(bootstrap(([1]*l_fit+[0]*(count_fit-l_fit),), np.mean, confidence_level=0.95, method='percentile').standard_error)\n",
    "    smooth_lernability.append(np.divide(float(l_smth),float(count_smth)))\n",
    "    smooth_lernability_err.append(bootstrap(([1]*l_smth+[0]*(count_smth-l_smth),), np.mean, confidence_level=0.95, method='percentile').standard_error)\n",
    "    \n",
    "    true_best_error_ode_final.append(np.mean(true_best_error_ode))\n",
    "    data_best_error_ode_final.append(np.mean(data_best_error_ode))\n",
    "    data_best_error_ode_final_err.append(np.std(data_best_error_ode,ddof=1)/np.sqrt(np.size(data_best_error_ode)))\n",
    "\n",
    "    true_best_error_fit_final.append(np.mean(true_best_error_fit))\n",
    "    data_best_error_fit_final.append(np.mean(data_best_error_fit))\n",
    "    data_best_error_fit_final_err.append(np.std(data_best_error_fit,ddof=1)/np.sqrt(np.size(data_best_error_fit)))\n",
    "\n",
    "    true_best_error_smth_final.append(np.mean(true_best_error_smth))\n",
    "    data_best_error_smth_final.append(np.mean(data_best_error_smth))\n",
    "    data_best_error_smth_final_err.append(np.std(data_best_error_smth,ddof=1)/np.sqrt(np.size(data_best_error_smth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b423d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store={\n",
    "    's_array':s_array,\n",
    "    'ode_lernability':ode_lernability,\n",
    "    'ode_lernability_err':ode_lernability_err,\n",
    "    'fit_lernability':fit_lernability,\n",
    "    'fit_lernability_err':fit_lernability_err,\n",
    "    'smooth_lernability':smooth_lernability,\n",
    "    'smooth_lernability_err':smooth_lernability_err,\n",
    "    'true_best_error_ode_final':true_best_error_ode_final,\n",
    "    'true_best_error_fit_final':true_best_error_fit_final,\n",
    "    'true_best_error_smth_final':true_best_error_smth_final,\n",
    "    'data_best_error_ode_final':data_best_error_ode_final,\n",
    "    'data_best_error_fit_final':data_best_error_fit_final,\n",
    "    'data_best_error_smth_final':data_best_error_smth_final,\n",
    "    'data_best_error_ode_final_err':data_best_error_ode_final_err,\n",
    "    'data_best_error_fit_final_err':data_best_error_fit_final_err,\n",
    "    'data_best_error_smth_final_err':data_best_error_smth_final_err,\n",
    "}\n",
    "with open('Plots/lernability.pkl','wb') as file:\n",
    "    pickle.dump(data_store,file=file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
